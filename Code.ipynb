{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "from tf2cv.model_provider import get_model as tf2cv_get_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def extract_from_folder(root_dir, is_extract=False, network='efficientnet_b0'):\n",
    "  image_paths, image_labels = utils.get_images(root_dir)\n",
    "\n",
    "  images = tf.stack(list(map(utils.load_and_preprocess_image, image_paths)))\n",
    "  labels = tf.stack(image_labels)\n",
    "\n",
    "  if is_extract:\n",
    "    net = tf2cv_get_model(network, pretrained=True, data_format=\"channels_last\")\n",
    "    images = net.features(images)\n",
    "\n",
    "  return np.squeeze(images.numpy()), labels.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不同的划分比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in [0.1,0.3,0.2,0.4]:\n",
    "  accu = []\n",
    "  for seed in range(1,21):\n",
    "    data_train = np.load(f'{s}dataset_{seed}_train_efficientnet_b0.npz')\n",
    "    data_test = np.load(f'{s}dataset_{seed}_test_efficientnet_b0.npz')\n",
    "    train_X, train_y = data_train['X'], data_train['y']\n",
    "    test_X, test_y = data_test['X'], data_test['y']\n",
    "\n",
    "    model = CatBoostClassifier(iterations=350, use_best_model=True, task_type='GPU')\n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y), verbose=False)\n",
    "    accu.append(model.score(test_X, test_y) * 100)\n",
    "\n",
    "  print(f'test_size={s}', np.mean(accu), np.std(accu), accu)      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不同的采样方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay = []\n",
    "mvs = []\n",
    "ber = []\n",
    "\n",
    "for seed in range(1,21):\n",
    "    data_train = np.load(f'0.2dataset_{seed}_train_efficientnet_b0.npz')\n",
    "    data_test = np.load(f'0.2dataset_{seed}_test_efficientnet_b0.npz')\n",
    "    train_X, train_y = data_train['X'], data_train['y']\n",
    "    test_X, test_y = data_test['X'], data_test['y']\n",
    "\n",
    "    model = CatBoostClassifier(iterations=350, use_best_model=True, bootstrap_type='Bernoulli', task_type='GPU')\n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y), verbose=False)\n",
    "    ber.append(model.score(test_X, test_y) * 100)\n",
    "\n",
    "    model = CatBoostClassifier(iterations=350, use_best_model=True, bootstrap_type='MVS', task_type='GPU')\n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y), verbose=False)\n",
    "    mvs.append(model.score(test_X, test_y) * 100)\n",
    "\n",
    "    model = CatBoostClassifier(iterations=350, use_best_model=True, bootstrap_type='Bayesian', task_type='GPU')\n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y), verbose=False)\n",
    "    bay.append(model.score(test_X, test_y) * 100)\n",
    "\n",
    "print('Bernoulli: ', np.mean(ber), np.std(ber))\n",
    "print('Bayesian: ', np.mean(bay), np.std(bay))\n",
    "print('MVS: ', np.mean(mvs), np.std(mvs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各指标具体结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "tprs=[]\n",
    "aucs=[]\n",
    "mean_fpr=np.linspace(0,1,100)\n",
    "\n",
    "jianqie_precision = []\n",
    "jianqie_recall = []\n",
    "jianqie_fscore = []\n",
    "zhangla_precision = []\n",
    "zhangla_recall = []\n",
    "zhangla_fscore = []\n",
    "\n",
    "for seed in range(1,21):\n",
    "    data_train = np.load(f'0.2dataset_{seed}_train_efficientnet_b0.npz')\n",
    "    data_test = np.load(f'0.2dataset_{seed}_test_efficientnet_b0.npz')\n",
    "    train_X, train_y = data_train['X'], data_train['y']\n",
    "    test_X, test_y = data_test['X'], data_test['y']\n",
    "\n",
    "    model = CatBoostClassifier(iterations=350, use_best_model=True, task_type='GPU')\n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y), verbose=False)\n",
    "\n",
    "    print(classification_report(test_y, model.predict(test_X), target_names=['剪切', '张拉'], digits=5))\n",
    "\n",
    "    precision, recall, fscore, support=score(test_y, model.predict(test_X))\n",
    "    jianqie_precision.append(precision[0])\n",
    "    jianqie_recall.append(recall[0])\n",
    "    jianqie_fscore.append(fscore[0])\n",
    "    zhangla_precision.append(precision[1])\n",
    "    zhangla_recall.append(recall[1])\n",
    "    zhangla_fscore.append(fscore[1])\n",
    "\n",
    "    y_pred = model.predict_proba(test_X)\n",
    "    y_pred = y_pred[:,1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(test_y, y_pred)\n",
    "    tprs.append(np.interp(mean_fpr,fpr,tpr))\n",
    "    tprs[-1][0]=0.0\n",
    "\n",
    "    roc_auc=auc(fpr,tpr)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "mean_tpr=np.mean(tprs, axis=0)\n",
    "\n",
    "mean_tpr[-1]=1.0\n",
    "mean_auc=auc(mean_fpr,mean_tpr) #计算平均AUC值\n",
    "sns.set(rc={'figure.dpi': 300, 'axes.facecolor': 'WhiteSmoke'})\n",
    "plt.plot(mean_fpr,mean_tpr,label=r'Mean ROC (area=%0.2f)'%mean_auc)\n",
    "plt.plot([0, 1], [0, 1], color='orange', linestyle='--', label='Random')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(fancybox=True,shadow=True)\n",
    "plt.savefig(\"roc_curve.jpg\", bbox_inches='tight',dpi=500)\n",
    "\n",
    "jianqie_precision = np.array(jianqie_precision) * 100\n",
    "jianqie_recall = np.array(jianqie_recall) * 100\n",
    "jianqie_fscore = np.array(jianqie_fscore) * 100\n",
    "zhangla_precision = np.array(zhangla_precision) * 100\n",
    "zhangla_recall = np.array(zhangla_recall) * 100\n",
    "zhangla_fscore = np.array(zhangla_fscore) * 100\n",
    "\n",
    "print(np.mean(jianqie_precision), np.std(jianqie_precision))\n",
    "print(np.mean(jianqie_recall), np.std(jianqie_recall))\n",
    "print(np.mean(jianqie_fscore), np.std(jianqie_fscore))\n",
    "print(np.mean(zhangla_precision), np.std(zhangla_precision))\n",
    "print(np.mean(zhangla_recall), np.std(zhangla_recall))\n",
    "print(np.mean(zhangla_fscore), np.std(zhangla_fscore))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不同的特征提取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T13:45:34.350362Z",
     "start_time": "2023-04-14T12:38:15.723127Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = ['efficientnet_b0', 'resnet50', 'densenet161']\n",
    "\n",
    "for s in [0.2]:\n",
    "    for net in network:\n",
    "      accu = []\n",
    "      for seed in range(1,21):\n",
    "        data_train = np.load(f'{s}dataset_{seed}_train_{net}.npz')\n",
    "        data_test = np.load(f'{s}dataset_{seed}_test_{net}.npz')\n",
    "        train_X, train_y = data_train['X'], data_train['y']\n",
    "        test_X, test_y = data_test['X'], data_test['y']\n",
    "\n",
    "        model = CatBoostClassifier(iterations=350, use_best_model=True, verbose=False, task_type='GPU')\n",
    "        model.fit(train_X, train_y, eval_set=(test_X, test_y), verbose=False)\n",
    "        accu.append(model.score(test_X, test_y) * 100)\n",
    "      print(f'test_size={s}, {net}', np.mean(accu), np.std(accu), accu)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不同的机器学习方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-15T21:26:22.421439Z",
     "start_time": "2023-04-15T21:26:17.172136Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "\n",
    "svm = []\n",
    "knn = []\n",
    "lr = []\n",
    "gnb = []\n",
    "rt = []\n",
    "\n",
    "for seed in range(1,21):\n",
    "    data_train = np.load(f'0.2dataset_{seed}_train_efficientnet_b0.npz')\n",
    "    data_test = np.load(f'0.2dataset_{seed}_test_efficientnet_b0.npz')\n",
    "    train_X, train_y = data_train['X'], data_train['y']\n",
    "    test_X, test_y = data_test['X'], data_test['y']\n",
    "\n",
    "    model = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "    model.fit(train_X, train_y)\n",
    "    knn.append(model.score(test_X, test_y) * 100)\n",
    "\n",
    "    model= LogisticRegression(max_iter=100)\n",
    "    model.fit(train_X, train_y)\n",
    "    lr.append(model.score(test_X, test_y) * 100)\n",
    "    \n",
    "    model = GaussianNB()\n",
    "    model.fit(train_X, train_y)\n",
    "    gnb.append(model.score(test_X, test_y) * 100)\n",
    "\n",
    "    model= DecisionTreeClassifier(random_state=8)\n",
    "    model.fit(train_X, train_y)\n",
    "    rt.append(model.score(test_X, test_y) * 100)\n",
    "\n",
    "print('KNN:', np.mean(knn), np.std(knn))\n",
    "print('LR:', np.mean(lr), np.std(lr))\n",
    "print('GNB:', np.mean(gnb), np.std(gnb))\n",
    "print('DT:', np.mean(rt), np.std(rt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深度学习特征提取的有效性"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 声谱图特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('声音数据集no_extract.npz')\n",
    "X, y = data['X'], data['y']\n",
    "X = X.reshape(161, -1)\n",
    "\n",
    "for s in [0.2]:\n",
    "  accu = []\n",
    "  for seed in range(1,6):\n",
    "    train_aug_X = []\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=s, random_state=seed, shuffle=True)\n",
    "    model = CatBoostClassifier(iterations=450, task_type=\"GPU\", use_best_model=True, verbose=False)\n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y), verbose=False)\n",
    "    accu.append(model.score(test_X, test_y) * 100)\n",
    "\n",
    "  print(f'test_size={s}', np.mean(accu), np.std(accu), accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA降维后特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data = np.load('声音数据集no_extract.npz')\n",
    "X, y = data['X'], data['y']\n",
    "X = X.reshape(161, -1)\n",
    "\n",
    "n_components = 161\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "for s in [0.2]:\n",
    "  accu = []\n",
    "  for seed in range(1,6):\n",
    "    train_aug_X = []\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=s, random_state=seed, shuffle=True)\n",
    "    model = CatBoostClassifier(iterations=700, use_best_model=True, verbose=False, task_type=\"GPU\")\n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y), verbose=False)\n",
    "    accu.append(model.score(test_X, test_y) * 100)\n",
    "\n",
    "  print(f'test_size={s}', np.mean(accu), np.std(accu), accu)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 深度学习提取的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('声音数据集.npz')\n",
    "X, y = data['X'], data['y']\n",
    "\n",
    "for s in [0.2]:\n",
    "  accu = []\n",
    "  for seed in range(1,6):\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=s, random_state=seed, shuffle=True)\n",
    "    model = CatBoostClassifier(iterations=350, task_type=\"GPU\", use_best_model=True, verbose=False)\n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y), verbose=False)\n",
    "    accu.append(model.score(test_X, test_y) * 100)\n",
    "\n",
    "  print(f'test_size={s}', np.mean(accu), np.std(accu), accu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
